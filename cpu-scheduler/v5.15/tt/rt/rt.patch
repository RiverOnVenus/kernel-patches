diff --git a/kernel/sched/bs.c b/kernel/sched/bs.c
index 778a538b3c6e..c33094d62171 100644
--- a/kernel/sched/bs.c
+++ b/kernel/sched/bs.c
@@ -552,7 +552,7 @@ static void
 check_preempt_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr)
 {
 	if (pick_next_entity(cfs_rq, curr) != curr)
-		resched_curr(rq_of(cfs_rq));
+		resched_curr_lazy(rq_of(cfs_rq));
 }
 
 static void
@@ -595,7 +595,7 @@ static void check_preempt_wakeup(struct rq *rq, struct task_struct *p, int wake_
 	return;
 
 preempt:
-	resched_curr(rq);
+	resched_curr_lazy(rq);
 }
 
 #ifdef CONFIG_SMP
@@ -1007,7 +1007,7 @@ static void task_fork_fair(struct task_struct *p)
 		update_curr(cfs_rq);
 
 		if (sysctl_sched_child_runs_first)
-			resched_curr(rq);
+			resched_curr_lazy(rq);
 	}
 
 	rq_unlock(rq, &rf);
diff --git a/kernel/sched/bs.h b/kernel/sched/bs.h
index 28f2f4507010..334505311b8b 100644
--- a/kernel/sched/bs.h
+++ b/kernel/sched/bs.h
@@ -148,7 +148,7 @@ prio_changed_fair(struct rq *rq, struct task_struct *p, int oldprio)
 	 */
 	if (task_current(rq, p)) {
 		if (p->prio > oldprio)
-			resched_curr(rq);
+			resched_curr_lazy(rq);
 	} else
 		check_preempt_curr(rq, p, 0);
 }
